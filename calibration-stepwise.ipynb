{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Well Calibrated Severity Scores\n",
    "## Model Development\n",
    "### C.V. Cosgriff, MIT Critical Data\n",
    "\n",
    "Previous work by our group focused on applying a _sequential_ or _stepwise_ approach to mortality modeling to improve the model calibration of illness severity scores. That is, fitting mortality models within a high-risk subset as defined by a previous model; it was hypothesized that the distribution of case severity in subcohort would lead to models that are better calibrated with respect to mortality prediction in this subcohort as traditional models such as APACHE have been shown to perform poorly with respect to prognostication in this cohort. However, given the volume and granulairty and volume of EHR databases it may possible to achieve well-calibrated models using the full-cohort. \n",
    "\n",
    "In previously unpublished work by the LCP, the model trained via the sequential approach had superior calibration by visual inspection of the graphs provided, but the model trained on the whole cohort had superior discriminatory capability, and comparable calibration.\n",
    "\n",
    "The goal of this notebook is to reproduce and reframe that prior work. Using the project's previous code as a starting point, the current state-of-the-art for predictive modeling with structured data will be employed in both the full-cohort and high-risk cohort, and the models discriminative ability and calibration will be examined in the high-risk cohort. Thus, the goal of this study is to determine which strategy leads to models that can accurately forecast mortality in high-risk subsets where previous models have struggled.\n",
    "\n",
    "With respect to the modeling approaches, we'll implement a generalized linear model similar to APACHE IV, but, given the extremely large number of features we will impose regularization to reduce model complexity and prevent overfitting; we will employe $L^2$ penalization also known as ridge regression. We will also implement a tree based approach as these have been exceedingly successful in recent works. Specifically, we will use a gradient boosted tree approach as implemented by the _extreme gradient boosting_ algorithim in `xgBoost` _(XGBoost: A Scalable Tree Boosting System, arXiv:1603.02754 [cs.LG])_. More details on implementation will be discussed below.\n",
    "\n",
    "__Notebook Outline:__\n",
    "* Envrionment preparation\n",
    "* Load full cohort extraction (features & labels)\n",
    "* Train models on full cohort\n",
    "    * Penalized linear model ($L^2$, ridge regression)\n",
    "    * Extreme Gradient Boosting (with Isotonic Regression)\n",
    "* Train models on high-risk subset of full cohort\n",
    "    * Penalized linear model ($L^2$, ridge regression)\n",
    "    * Extreme Gradient Boosting (with Isotonic Regression)\n",
    "* Compare full-cohort and high-risk cohort models on high-risk subset\n",
    "    * Discrimination\n",
    "    * Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Environment Setup\n",
    "\n",
    "Here we'll load the standard data science stack, preprocessing, linear model, and model evalutaion tools from `scikit-learn`, and gradient boosting classifier from `xgboost`. We are using version 0.19.1 of `scikit-learn` and version 0.71 of `xgboost`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data science stack\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine learning tools\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "# Extreme gradient boosting model\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Graphing stuff\n",
    "# \"Tableau 20\" colors as RGB for plotting\n",
    "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),    \n",
    "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),    \n",
    "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),    \n",
    "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),    \n",
    "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]  \n",
    "  \n",
    "# Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts\n",
    "for i in range(len(tableau20)):    \n",
    "    r, g, b = tableau20[i]    \n",
    "    tableau20[i] = (r / 255., g / 255., b / 255.)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load Data\n",
    "\n",
    "We now load the cohort data. The files are stored as separate CSV files, and were previously extracted by LCP from the full eICU-CRD. The dataset inclues all features used in determining the APACHE score as well as an expanded set of features engineered by the LCP. This portion of the code was adapted from `run_sequential_model.py` which was written by Aaron Kaufman. Of note, his script contains code for loading 24 hour or 48 hour data based on a flag `TEST_ONLY_24` and we'll adapt their code to use the 24 hour data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataset files\n",
    "\n",
    "# I was working under the presumption that sequential_model_features_n contained the full cohort\n",
    "# but in fact they contain only the high risk cohort and I do not have the full dataset.\n",
    "\n",
    "# TODO: Once we have full dataset, replace these paths with those files\n",
    "\n",
    "data_set_0 = pd.read_csv('./data/sequential_model_features0.csv')\n",
    "data_set_1 = pd.read_csv('./data/sequential_model_features1.csv')\n",
    "data_set_2 = pd.read_csv('./data/sequential_model_features2.csv')\n",
    "data_set_3 = pd.read_csv('./data/sequential_model_features3.csv')\n",
    "data_set_4 = pd.read_csv('./data/sequential_model_features4.csv')\n",
    "\n",
    "# concatetnate into a single dataset\n",
    "data_set = pd.concat([data_set_0, data_set_1, data_set_2, data_set_3, data_set_4])\n",
    "\n",
    "# remove data_set_n from memory\n",
    "del data_set_0\n",
    "del data_set_1\n",
    "del data_set_2\n",
    "del data_set_3\n",
    "del data_set_4\n",
    "\n",
    "# only include 24h data; adapred from old code\n",
    "columns = data_set.columns.values.tolist()\n",
    "col_24h = [] # collection of all the column names for 24h\n",
    "for col in columns:\n",
    "    if '48h' in col:\n",
    "        continue\n",
    "    if col == 'APACHE Predicted' or col == 'Death':\n",
    "        continue\n",
    "    else:\n",
    "        col_24h.append(col)\n",
    "\n",
    "data_set = data_set[col_24h + ['APACHE Predicted', 'Death']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll form a train-test split for use throughout the modeling process. The previous file, `run_sequential.py` used the first file as the held out testing set, but I am unsure if these files have any inherent ordering left over from the extraction and feature engineering, and so to avoid this problem we'll perform a random train/test split of the data. We'll hold out 25% of the data for final testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data_set, test_size = 0.25, random_state = 42)\n",
    "del data_set # no longer needed in memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split up the dataset into features and labels. We'll also store the APACHE predicted mortalities in another array as these are not meant to be used as a feature but will be used later when splitting off the high-risk subset of the cohort and for examining the discriminative ability and calibration of the original APACHE prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_apache = train.loc[:, 'APACHE Predicted'] # APACHE probabilities\n",
    "train_labels = train.loc[:, 'Death']  # Labels\n",
    "train_features = train.iloc[:, :-2]  # Features only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to implement the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Full Cohort Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ridge Logistic Regression__\n",
    "\n",
    "Our first model is a linear model similar to that used in the development of APACHE IV. As we have many variables, we choose to constrain model complexity using a $L^2$ regularization, and thus will train a ridge logistic regression model. For selection of $\\lambda$, which `scikit-learn` calls $\\alpha$, we'll use cross validation; because the nature of this model's formulation has a highly efficient implemntation of leave-one-out cross validation (LOO-CV) we'll use the generalized CV as implemented in the `RidgeClassiferCV` function.  \n",
    "\n",
    "Unlike tree based approaches, ridge regression requires features be of the same scale for proper performance. It is also not robust to missing data. As such, we'll employ mean imputation, followed by scaling and centering of the features, and then ridge regression with LOO-CV with a $\\lambda$ range of 1 to 2,000 with a stepsize of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_classifier = Pipeline([('impute', Imputer()),\n",
    "                       ('center_scale', StandardScaler()),\n",
    "                       ('ridge', RidgeClassifierCV(alphas=np.arange(1., 2000., 10.)))])\n",
    "ridge_classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extreme Gradient Boosting__  \n",
    "\n",
    "As compared to logistic regression, which directly minimizes the log-loss via MLE, boosted trees are typically poorly calibrated classifiers. Training them to directly minimize log-loss may overcome some of this, but has been shown to produce subpar results. However, they can be greatly improved via approaches such as Platt Scaling and Isotonic Regression _(Obtaining Calibrated Probabilities from Boosting, arXiv:1207.1403 [cs.LG])_. We will therefore use isotonic regression to calibrate the gradient boosted tree model. This will be implemented following steps:\n",
    "* Create a split in the data, saving 25% of the training data as a calibration set for isotonic regression\n",
    "    * We do this as using the same data the model was trained will result in biased result (see the above paper)\n",
    "* Using the training set (75% of original training data) determine hyperparameters by 5-fold cross validation\n",
    "* Fit model with optimal hyperparameters on full training set (75% of original training data)\n",
    "* Calibrate model with isotonic regression using calibration set (25% of original training data)\n",
    "\n",
    "Of note, hyperparameters will be obtained by a random sampling of the hyperparaemter space, as opposed to an exhaustive grid search, as Bergstra et al. showed this to be superior whilst remaining computationally cheaper _(Journal of Machine Learning Research 13 (2012) 281-30)_.\n",
    "\n",
    "We begin by creating the calibration set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, calib_X, train_y, calib_y = train_test_split(train_features, train_labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then perform a cross validated search of the hyperparameter space, randomly sampling the grid 250 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective':['binary:logistic'],\n",
    "          'learning_rate': [0.01, 0.05, 0.10],\n",
    "          'max_depth': [3, 6, 9, 12],\n",
    "          'min_child_weight': [6, 8, 10, 12],\n",
    "          'silent': [True],\n",
    "          'subsample': [0.6, 0.8, 1],\n",
    "          'colsample_bytree': [0.5, 0.75, 1],\n",
    "          'n_estimators': [500, 1000]}\n",
    "K = 5\n",
    "xgb_model = XGBClassifier()\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)\n",
    "cv_grid_search = RandomizedSearchCV(xgb_model, param_distributions=params, n_iter=100, scoring='roc_auc',\n",
    "                                    n_jobs=48, cv=skf.split(train_X, train_y), verbose=1, random_state=42 )\n",
    "cv_grid_search.fit(train_X, train_y)\n",
    "print(cv_grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run this optimal estimator on the full training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier = # output from above here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we calibrate the model on the held out calibration set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifer_ir = CalibrateClassifierCV(base_estimator=xgb_classifier, method='isotonic', cv='prefit')\n",
    "xgb_classifer_ir.fit(calib_X, calib_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - High-risk Models\n",
    "\n",
    "Again, we'll simply reproduce the steps for model training used in `run_sequential_model.py`, this time training the models on the high-risk subset. We start with feature normalization followed by training a logistic regression, ridge regression, random forest, AdaBoost, and a deep feed forward network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_HR = train_data.loc[(train_apache > 0.10), 'Death'] \n",
    "train_features_HR = train_data.iloc[(train_apache > 0.10), :-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then produce the same models as above. Because are only changing the training data, the process will be less verbose. Unless otherwise stated, everything is as above.\n",
    "\n",
    "__Ridge Logistic Regression__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_classifier_HR = Pipeline([('impute', Imputer()),\n",
    "                       ('center_scale', StandardScaler()),\n",
    "                       ('ridge', RidgeClassifierCV(alphas=np.arange(1., 2000., 10.)))])\n",
    "ridge_classifier_HR.fit(train_features_HR, train_labels_HR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Extreme Gradient Boosting__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As above, split off a calibration set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_HR, calib_X_HR, train_y_HR, calib_y_HR = train_test_split(train_features_HR, train_labels_HR, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then 5-fold cross validated grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective':['binary:logistic'],\n",
    "          'learning_rate': [0.01, 0.05, 0.10],\n",
    "          'max_depth': [3, 6, 9, 12],\n",
    "          'min_child_weight': [6, 8, 10, 12],\n",
    "          'silent': [True],\n",
    "          'subsample': [0.6, 0.8, 1],\n",
    "          'colsample_bytree': [0.5, 0.75, 1],\n",
    "          'n_estimators': [500, 1000]}\n",
    "K = 5\n",
    "xgb_model = XGBClassifier()\n",
    "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)\n",
    "cv_grid_search = RandomizedSearchCV(xgb_model, param_distributions=params, n_iter=100, scoring='roc_auc',\n",
    "                                    n_jobs=48, cv=skf.split(train_X_HR, train_y_HR), verbose=1, random_state=42 )\n",
    "cv_grid_search.fit(train_X_HR, train_y_HR)\n",
    "print(cv_grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then run this optimal estimator on the full training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifier_HR = # output from above here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude, again, by calibrating our model on the held out calibration set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_classifer_ir_HR = CalibrateClassifierCV(base_estimator=xgb_classifier_HR, method='isotonic', cv='prefit')\n",
    "xgb_classifer_ir_HR.fit(calib_X_HR, calib_y_HR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Comparison of Approaches\n",
    "\n",
    "We'll now evaluate these models on discriminatory capability and calibration. We first need to construct our testing data from the original train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_apache = test.loc[:, 'APACHE Predicted']\n",
    "test_labels = test.loc[(test_apache > 0.10), 'Death']\n",
    "test_features = test.iloc[(test_apache > 0.10), :-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discrimination, Full Cohort Models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_hat_ridge = ridge_classifier.predict_proba(test_features)\n",
    "roc_ridge = roc_curve(test_labels, f_hat_ridge[:, 1])\n",
    "auc_ridge = roc_auc_score(y_test, f_hat_ridge[:, 1])\n",
    "\n",
    "f_hat_xgb = ha_xgb.predict_proba(test_features)\n",
    "roc_xgb = roc_curve(test_labels, f_hat_xgb[:, 1])\n",
    "auc_xgb = roc_auc_score(y_test, f_hat_xgb[:, 1])\n",
    "\n",
    "plt.plot(roc_ridge[0], roc_ridge[1], color = tableau20[7], label='Ridge\\n(area = %0.3f)'.format(auc_ridge))\n",
    "plt.plot(roc_xgb[0], roc_xgb[1], color = tableau20[9], label='GBM\\n(area = %0.3f)'.format(auc_xgb))\n",
    "plt.plot([0, 1], [0, 1], color= tableau20[0])\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC: Full Cohort Models')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calibration, Full Cohort Models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Discrimination, High-risk Subset Models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calibration, High-risk Subset Models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br /><br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
